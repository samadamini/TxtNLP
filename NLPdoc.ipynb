{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLPdoc.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMfQSCsAKU1nsZuWyI+Clzf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samadamini/TxtNLP/blob/master/NLPdoc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHvy2_iA5BnB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "fb785aab-404e-41ba-dd22-4cacbe1d4dcc"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.11.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnTcJcjO5KIB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f598b120-12d0-4ca9-bc81-00d8d35e5d17"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZYndPrq5lXn",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "c5e930d1-829e-4c9d-cc3e-d2c5dbaa29e5"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-35adb5fd-8867-48dc-a144-3d6ff2fd9b01\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-35adb5fd-8867-48dc-a144-3d6ff2fd9b01\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving data_doc.csv to data_doc.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plt_lDIo5n96",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "df = pd.read_csv(io.BytesIO(uploaded['data_doc.csv']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssOPYrpI5uQq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "512e6979-77ae-4048-9f5c-7e254cc32b19"
      },
      "source": [
        "df.dropna(subset=['Participant'],inplace=True)\n",
        "df.isnull().sum()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unnamed: 0              0\n",
              "Participant             0\n",
              "age_at_event            0\n",
              "sex                     0\n",
              "apoe                    7\n",
              "diagnosis               0\n",
              "cog_status_at_death    57\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jGvSoLR57jf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "dc9c62ec-f290-4381-e2b1-56528feffdab"
      },
      "source": [
        "df.diagnosis.loc[(df['diagnosis'] > 0)] = 1\n",
        "df.diagnosis.loc[(df['diagnosis'] <= 0)] = 0\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_with_indexer(indexer, value)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niCMt6oUAO7b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dfn = df.convert_dtypes()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-5N6tLjIero",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "d1ce8eef-85da-4727-8798-756573e67290"
      },
      "source": [
        "dfn.dtypes"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unnamed: 0               Int64\n",
              "Participant             string\n",
              "age_at_event             Int64\n",
              "sex                      Int64\n",
              "apoe                     Int64\n",
              "diagnosis                Int64\n",
              "cog_status_at_death    float64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqJP4cME96GR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "63455ae9-69cc-4818-e09f-36a955fd4977"
      },
      "source": [
        "import re\n",
        "def clean_txt(txt):\n",
        "  txt = re.sub(\"'\",\"\",txt)\n",
        "  txt = re.sub(\"(\\\\W)+\",\" \",txt)\n",
        "  return txt\n",
        "dfn.Participant.apply(clean_txt)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       Single Widowed Right Button my right hand shi...\n",
              "1       Very well Id like to hear that Both On the on...\n",
              "2       Widow Right No I dont think so theres so many...\n",
              "3       As long as youre not gonna use it against me ...\n",
              "4       Okay Well I know her name was Ann Anna Thomps...\n",
              "                             ...                        \n",
              "187     Im divorced Right handed Not primarily I have...\n",
              "188     Right handed No Our two daughters I dont thin...\n",
              "189     Okay Yes Married Right handed No I only gradu...\n",
              "190     Unintelligible Alright PhD Business Administr...\n",
              "191     I had I had it before yeah Yeah Right Married...\n",
              "Name: Participant, Length: 192, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qVV9dsX_lNd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "df_train, df_test = train_test_split(dfn,test_size=0.20, random_state=21)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syHlIi_-Lstf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "2b181aa7-d389-442e-b8c8-8b421a14759c"
      },
      "source": [
        "df_train.reset_index(drop=True, inplace=True)\n",
        "df_test.reset_index(drop=True, inplace=True)\n",
        "df_train.head(2)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Participant</th>\n",
              "      <th>age_at_event</th>\n",
              "      <th>sex</th>\n",
              "      <th>apoe</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>cog_status_at_death</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>129</td>\n",
              "      <td>I hope so.    I'll tell you no, I don't, no....</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "      <td>34</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>141</td>\n",
              "      <td>P1:  We was, I thought we could go, s-, couple...</td>\n",
              "      <td>83</td>\n",
              "      <td>2</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ... cog_status_at_death\n",
              "0         129  ...                 3.0\n",
              "1         141  ...                 3.0\n",
              "\n",
              "[2 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WF--ajch-Uvt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_split(text1):\n",
        "  l_total = []\n",
        "  l_parcial = []\n",
        "  if len(text1.split())//150 >0:\n",
        "    n = len(text1.split())//150\n",
        "  else: \n",
        "    n = 1\n",
        "  for w in range(n):\n",
        "    if w == 0:\n",
        "      l_parcial = text1.split()[:200]\n",
        "      l_total.append(\" \".join(l_parcial))\n",
        "    else:\n",
        "      l_parcial = text1.split()[w*150:w*150 + 200]\n",
        "      l_total.append(\" \".join(l_parcial))\n",
        "  return l_total\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9Jtu0K-J7T9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "a86a569e-a378-4f61-a999-f721d3266083"
      },
      "source": [
        "df_train['txt_split'] = df_train['Participant'].apply(get_split)\n",
        "df_test['txt_split'] = df_test['Participant'].apply(get_split)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsMICoMtjhJr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f7314e4f-dfd2-47d3-fbe1-53da01aef2c3"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6OjjBaXmmLR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = []\n",
        "for i in range(len(df_train.txt_split)):\n",
        "  for j in range(len(df_train.txt_split.iloc[i])):\n",
        "    label = df_train.diagnosis.iloc[i]\n",
        "    labels.append(label)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNEUGQ3zj3BU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "token_type_ids = []\n",
        "# For every sentence...\n",
        "for j in range(len(df_train.txt_split)):\n",
        "  for i in range(len(df_train.txt_split.iloc[j])):\n",
        "      # `encode_plus` will:\n",
        "      #   (1) Tokenize the sentence.\n",
        "      #   (2) Prepend the `[CLS]` token to the start.\n",
        "      #   (3) Append the `[SEP]` token to the end.\n",
        "      #   (4) Map tokens to their IDs.\n",
        "      #   (5) Pad or truncate the sentence to `max_length`\n",
        "      #   (6) Create attention masks for [PAD] tokens.\n",
        "      encoded_dict = tokenizer.encode_plus(\n",
        "                          #sentences1[i], # Sentence to encode.\n",
        "                          df_train.txt_split.iloc[j][i],\n",
        "                          add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                          max_length = 512,           # Pad & truncate all sentences.\n",
        "                          pad_to_max_length = True,\n",
        "                          return_attention_mask = True,\n",
        "                          return_token_type_ids = False,   # Construct attn. masks.\n",
        "                          return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                    )\n",
        "      \n",
        "      # Add the encoded sentence to the list.    \n",
        "      input_ids.append(encoded_dict['input_ids'])\n",
        "      \n",
        "      # And its attention mask (simply differentiates padding from non-padding).\n",
        "      attention_masks.append(encoded_dict['attention_mask'])\n",
        "      #token_type_ids.append(encoded_dict['token_type_ids'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "#token_type_ids = torch.cat(token_type_ids, dim=0)\n",
        "labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "#print('Original: ', df_train.txt_split.iloc[0][0])\n",
        "#print('Token IDs:', input_ids[0])\n",
        "#print(i*j)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMGo29qVoSO_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a8879312-118f-4847-e292-90b033bf7869"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "#dataset = TensorDataset(input_ids, attention_masks, labels, token_type_ids)\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1,470 training samples\n",
            "  164 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W47Z6-b8pDIv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 8\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aa3y22ZpOgv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b12cbec0-99d1-44d1-c161-a85b55c6f36f"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "model.cuda()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYIU2QhFpTPB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 5e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvqFwYKkpeGw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "epochs = 3\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lL8yFz0pfmo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Li0sicH4pkEf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "le16TeOBpqak",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "outputId": "e71dedaa-f955-4fc9-f121-cc0983ac90bf"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        #b_token_type_ids = batch[3].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        #loss, logits = model(b_input_ids, \n",
        "                             #token_type_ids= b_token_type_ids, \n",
        "                             #attention_mask= b_input_mask, \n",
        "                             #labels= b_labels)\n",
        "        loss, logits = model(b_input_ids,  \n",
        "                             attention_mask= b_input_mask, \n",
        "                             labels= b_labels)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        #b_token_type_ids = batch[3].to(device)\n",
        "\n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            #(loss, logits) = model(b_input_ids, \n",
        "                                   #token_type_ids=b_token_type_ids, \n",
        "                                   #attention_mask=b_input_mask,\n",
        "                                   #labels=b_labels)\n",
        "            (loss, logits) = model(b_input_ids, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of    184.    Elapsed: 0:00:30.\n",
            "  Batch    80  of    184.    Elapsed: 0:01:01.\n",
            "  Batch   120  of    184.    Elapsed: 0:01:33.\n",
            "  Batch   160  of    184.    Elapsed: 0:02:05.\n",
            "\n",
            "  Average training loss: 0.54\n",
            "  Training epcoh took: 0:02:24\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.79\n",
            "  Validation Loss: 0.51\n",
            "  Validation took: 0:00:06\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of    184.    Elapsed: 0:00:33.\n",
            "  Batch    80  of    184.    Elapsed: 0:01:07.\n",
            "  Batch   120  of    184.    Elapsed: 0:01:40.\n",
            "  Batch   160  of    184.    Elapsed: 0:02:14.\n",
            "\n",
            "  Average training loss: 0.38\n",
            "  Training epcoh took: 0:02:34\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.58\n",
            "  Validation took: 0:00:06\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of    184.    Elapsed: 0:00:34.\n",
            "  Batch    80  of    184.    Elapsed: 0:01:07.\n",
            "  Batch   120  of    184.    Elapsed: 0:01:41.\n",
            "  Batch   160  of    184.    Elapsed: 0:02:15.\n",
            "\n",
            "  Average training loss: 0.24\n",
            "  Training epcoh took: 0:02:35\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "  Validation Loss: 0.57\n",
            "  Validation took: 0:00:06\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:07:52 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDL-gzLbkW8e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels_t = []\n",
        "for i in range(len(df_test.txt_split)):\n",
        "  for j in range(len(df_test.txt_split.iloc[i])):\n",
        "    label = df_test.diagnosis.iloc[i]\n",
        "    labels_t.append(label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09e7I1kBjzl6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for j in range(len(df_test.txt_split)):\n",
        "  for i in range(len(df_test.txt_split.iloc[j])):\n",
        "      # `encode_plus` will:\n",
        "      #   (1) Tokenize the sentence.\n",
        "      #   (2) Prepend the `[CLS]` token to the start.\n",
        "      #   (3) Append the `[SEP]` token to the end.\n",
        "      #   (4) Map tokens to their IDs.\n",
        "      #   (5) Pad or truncate the sentence to `max_length`\n",
        "      #   (6) Create attention masks for [PAD] tokens.\n",
        "      encoded_dict = tokenizer.encode_plus(\n",
        "                          df_test.txt_split.iloc[j][i],                      # Sentence to encode.\n",
        "                          add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                          max_length = 512,           # Pad & truncate all sentences.\n",
        "                          pad_to_max_length = True,\n",
        "                          return_attention_mask = True,   # Construct attn. masks.\n",
        "                          return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                    )\n",
        "      \n",
        "      # Add the encoded sentence to the list.    \n",
        "      input_ids.append(encoded_dict['input_ids'])\n",
        "      \n",
        "      # And its attention mask (simply differentiates padding from non-padding).\n",
        "      attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels_t = torch.tensor(labels_t, dtype=torch.long)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 16  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels_t)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1WRlJsMlw_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction_dataloader = DataLoader(prediction_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWAVItVRlndu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "39554b83-994a-46a4-8b02-39944b6a00d7"
      },
      "source": [
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 377 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzBmd-QjqUWZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c = -1\n",
        "acc = 0\n",
        "tie = 0\n",
        "for j in range(len(df_test.txt_split)):\n",
        "  a = 0\n",
        "  for i in range(len(df_test.txt_split.iloc[j])):\n",
        "    c +=1\n",
        "    if true_labels[c] == np.argmax(predictions[c]):\n",
        "      if i>-1:\n",
        "        a += 1\n",
        "  if (a - (len(df_test.txt_split.iloc[j]))/2) >0:\n",
        "    acc += 1\n",
        "  elif (a  - (len(df_test.txt_split.iloc[j]))/2) == 0:\n",
        "    tie += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1mQYtIiwhqg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "99bb878e-81d0-4abb-ce81-902952e9ba5a"
      },
      "source": [
        "print(f'Accuracy : {acc/len(df_test.txt_split)} \\n Tie : {tie/len(df_test.txt_split)}')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.8205128205128205 \n",
            " Tie : 0.05128205128205128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yY13V6rj_wBm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "821a3801-28c4-4406-8981-8a0d1fc893e2"
      },
      "source": [
        "import seaborn as sns\n",
        "ll = []\n",
        "for i in range(len(df_test.txt_split)):\n",
        "  li = len(df_test.txt_split.iloc[i])\n",
        "  ll.append(li)\n",
        "\n",
        "sns.distplot(ll)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fef9a078cc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhIq79An3yLn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fe8c2870-c70b-492b-9cc6-129e59ca3fe5"
      },
      "source": [
        "cc = 0\n",
        "for i in range(len(true_labels)):\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  if pred_labels_i == true_labels[i]:\n",
        "    cc += 1\n",
        "print(cc/len(true_labels))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8275862068965517\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}